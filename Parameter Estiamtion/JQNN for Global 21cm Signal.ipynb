{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvLpEBfyx5PN"
      },
      "outputs": [],
      "source": [
        "# pip install cuda-python==12.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx2VdsG6x5PP"
      },
      "outputs": [],
      "source": [
        "# pip install jax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xeh10LC9x5PP"
      },
      "outputs": [],
      "source": [
        "# pip install jaxlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEth22kLx5PP"
      },
      "outputs": [],
      "source": [
        "# pip install -U \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFJpcppHx5PP"
      },
      "outputs": [],
      "source": [
        "# pip install pennylane --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OV09GEUx5PQ"
      },
      "outputs": [],
      "source": [
        "# pip install scipy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3qXhy-yx5PQ"
      },
      "outputs": [],
      "source": [
        "# For Linux 64, Open MPI is built with CUDA awareness but this support is disabled by default.\n",
        "# To enable it, please set the environment variable OMPI_MCA_opal_cuda_support=true before\n",
        "# launching your MPI processes. Equivalently, you can set the MCA parameter in the command line:\n",
        "# mpiexec --mca opal_cuda_support 1 ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW9Y05fXx5PQ"
      },
      "source": [
        "# **Libs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Hm7LeBPx5PR"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "from math import sqrt\n",
        "\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as pnp\n",
        "from pennylane.operation import Operation, AnyWires\n",
        "\n",
        "import jax\n",
        "from jax import numpy as jnp\n",
        "from jax import random\n",
        "import optax\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['mathtext.fontset'] = 'cm'\n",
        "from matplotlib.ticker import (\n",
        "    AutoLocator, AutoMinorLocator)\n",
        "import seaborn as sns\n",
        "# %matplotlib\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from sklearn.decomposition import KernelPCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utciHDRWx5PR"
      },
      "outputs": [],
      "source": [
        "jax.config.update('jax_platform_name', 'gpu')       #Hard-set to run on GPU\n",
        "jax.config.update(\"jax_enable_x64\", True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iiv8ge-px5PS"
      },
      "outputs": [],
      "source": [
        "jax.devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICTJXARqx5PS"
      },
      "source": [
        "# **Data Generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhPtRzNsx5PT"
      },
      "outputs": [],
      "source": [
        "#Initial conditions\n",
        "Nf = 1024\n",
        "f0 = 1420.4057\n",
        "N = 10000 #no. of curves\n",
        "n = 2\n",
        "f00 = 78.1\n",
        "T0 = 2039.611\n",
        "a1 = -2.42096\n",
        "a2 = -0.08062\n",
        "a3 = 0.02898\n",
        "f = np.linspace(27,200,Nf)\n",
        "redshift = (f0/f)-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku1O-dEJx5PT"
      },
      "outputs": [],
      "source": [
        "#Data files\n",
        "\"\"\"Input with fs, fx, Nlw as params\"\"\"\n",
        "X_21 = np.loadtxt(\"Input_dTb_10k.csv\", delimiter =',').T\n",
        "Y_21 = np.loadtxt(\"Output_Params_10k_diff.csv\", delimiter =',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VX1MRP5x5PT"
      },
      "outputs": [],
      "source": [
        "#Signal+foreground+noise data files\n",
        "X_cfgn = np.loadtxt(\"SFGNC_in.csv\", delimiter =',')     #constant foreground\n",
        "Y_cfgn = np.loadtxt(\"SFGNC_out.csv\", delimiter =',')\n",
        "X_fgn = np.loadtxt(\"SFGNV_in.csv\", delimiter =',')      #varying foreground\n",
        "Y_fgn = np.loadtxt(\"SFGNV_out.csv\", delimiter =',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgoG87UIx5PT"
      },
      "outputs": [],
      "source": [
        "#class to generate foreground foreground\n",
        "class Foreground:\n",
        "    def __init__(self, T0, a1, a2, a3, N, f, f00, variation,random=False, constant_space=False):\n",
        "        \"\"\"\n",
        "        Initialize the Foreground object.\n",
        "\n",
        "        Parameters:\n",
        "            T0 (float): Parameter T0.\n",
        "            a1 (float): Parameter a1.\n",
        "            a2 (float): Parameter a2.\n",
        "            a3 (float): Parameter a3.\n",
        "            N (int): Number of samples.\n",
        "            f (list or array): List or array of frequencies.\n",
        "            f00 (float): Reference frequency.\n",
        "            constant_space (bool): Whether to use constant space or not.\n",
        "        \"\"\"\n",
        "        self.T0 = T0\n",
        "        self.a1 = a1\n",
        "        self.a2 = a2\n",
        "        self.a3 = a3\n",
        "        self.N = N\n",
        "        self.f = f\n",
        "        self.f00 = f00\n",
        "        self.var = variation\n",
        "        self.rand = random\n",
        "        self.constant_space = constant_space\n",
        "\n",
        "    def param_range(self, n=2):\n",
        "        \"\"\"\n",
        "        Generate parameter ranges.\n",
        "\n",
        "        Returns:\n",
        "            list of arrays: List of parameter ranges.\n",
        "        \"\"\"\n",
        "        a0_init = np.log10(self.T0)\n",
        "        var0,var1,var2,var3 = self.var\n",
        "        a0_range = np.linspace(a0_init*(1-var0),a0_init*(1+var0), n)\n",
        "        a1_range = np.linspace(self.a1*(1-var1),self.a1*(1+var1), n)\n",
        "        a2_range = np.linspace(self.a2*(1-var2),self.a2*(1+var2), n)\n",
        "        a3_range = np.linspace(self.a3*(1-var3),self.a3*(1+var3), n)\n",
        "        a0_range = np.sort(a0_range)\n",
        "        a1_range = np.sort(a1_range)\n",
        "        a2_range = np.sort(a2_range)\n",
        "        a3_range = np.sort(a3_range)\n",
        "        return [a0_range, a1_range, a2_range, a3_range]\n",
        "\n",
        "    def param_space(self):\n",
        "        \"\"\"\n",
        "        Generate parameter space.\n",
        "\n",
        "        Returns:\n",
        "            array: Parameter space array.\n",
        "        \"\"\"\n",
        "        param_range = self.param_range()\n",
        "        space = Space(param_range)\n",
        "        lhs = Lhs(lhs_type=\"classic\", criterion=None)\n",
        "        x = lhs.generate(space.dimensions, self.N)\n",
        "        return np.array(x)\n",
        "\n",
        "    def random_space(self):\n",
        "        \"\"\"\n",
        "        Generate constant parameter space.\n",
        "\n",
        "        Returns:\n",
        "            array: Constant parameter space array.\n",
        "        \"\"\"\n",
        "        np.random.seed(1234)\n",
        "        a0_init = np.log10(self.T0)\n",
        "        var0,var1,var2,var3 = self.var\n",
        "        a0_ = np.random.uniform(a0_init*(1-var0),a0_init*(1+var0),size=self.N)\n",
        "        a1_ = np.random.uniform(self.a1*(1-var1),self.a1*(1+var1),size=self.N)\n",
        "        a2_ = np.random.uniform(self.a2*(1-var2),self.a2*(1+var2),size=self.N)\n",
        "        a3_ = np.random.uniform(self.a3*(1-var3),self.a3*(1+var3),size=self.N)\n",
        "        return np.array([a0_, a1_, a2_, a3_]).T\n",
        "\n",
        "    def const_space(self):\n",
        "        \"\"\"\n",
        "        Generate constant parameter space.\n",
        "\n",
        "        Returns:\n",
        "            array: Constant parameter space array.\n",
        "        \"\"\"\n",
        "        a0_init = np.log10(self.T0)\n",
        "        a0_ = a0_init * np.ones(self.N)\n",
        "        a1_ = self.a1 * np.ones(self.N)\n",
        "        a2_ = self.a2 * np.ones(self.N)\n",
        "        a3_ = self.a3 * np.ones(self.N)\n",
        "        return np.array([a0_, a1_, a2_, a3_]).T\n",
        "\n",
        "    def get_params(self):\n",
        "        if self.constant_space == False and self.rand==False:\n",
        "            arr = self.param_space()\n",
        "        elif self.rand == False and self.constant_space==True:\n",
        "            arr = self.const_space()\n",
        "        elif self.rand == True and self.constant_space==False:\n",
        "            arr = self.random_space()\n",
        "        return arr\n",
        "\n",
        "\n",
        "    def generate_fore(self):\n",
        "        \"\"\"\n",
        "        Generate foreground.\n",
        "\n",
        "        Returns:\n",
        "            array: Foreground.\n",
        "        \"\"\"\n",
        "        arr = self.get_params()\n",
        "\n",
        "        Tf = []\n",
        "        for i in range(self.N):\n",
        "            a_arr = arr[i]\n",
        "            # Tf = []\n",
        "            for f_val in self.f:\n",
        "                logf = np.log10(f_val / self.f00)\n",
        "                tf = 0\n",
        "                for j in range(4):\n",
        "                    tf += a_arr[j] * logf ** j\n",
        "                Tf.append(tf)\n",
        "        T_fg = 10**np.array(Tf)\n",
        "        return T_fg.reshape(self.N,len(self.f))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmLnLJUsx5PT"
      },
      "outputs": [],
      "source": [
        "#Thermal Noise generation\n",
        "def therm_noise(foreground,del_nu,N_t):\n",
        "    return (foreground)/np.sqrt(del_nu*10**6*3600*N_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFqxbi2lx5PT"
      },
      "outputs": [],
      "source": [
        "fg = Foreground(T0,a1,a2,a3,N,f,f00,variation=[0.1,0,0.05,0.08],random=True,constant_space=False)\n",
        "fg1 = Foreground(T0,a1,a2,a3,N,f,f00,variation=[0.1,0.01,0.05,0.08],random=False,constant_space=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLth1Z53x5PU"
      },
      "outputs": [],
      "source": [
        "X_fg = fg.generate_fore()\n",
        "a_arr = fg.get_params()\n",
        "X_fg1 = fg1.generate_fore()\n",
        "a_arr1 = fg1.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoDbDvZax5PU"
      },
      "outputs": [],
      "source": [
        "X_n = therm_noise(X_fg,1,1000)\n",
        "X_n1 = therm_noise(X_fg1,1,1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIKjIUNKx5PU"
      },
      "outputs": [],
      "source": [
        "X_21.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKP7B2yUx5PU"
      },
      "outputs": [],
      "source": [
        "X_data_nf = X_21\n",
        "Y_data_nf = Y_21\n",
        "X_21_n = X_21 + X_n\n",
        "X_data_f = X_21+X_fg\n",
        "X_fgn = (X_21+X_fg*10**3+X_n)\n",
        "X_cfgn = (X_21+X_fg1*10**3+X_n1)\n",
        "Y_data_f = np.concatenate((Y_21,a_arr),axis=1)\n",
        "Y_data_fc = np.concatenate((Y_21,a_arr1),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY7Lvldgx5PU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "directory_path = '/home/somnath/akash/QNN21cm/Codes/'\n",
        "\n",
        "# Specify the filename (you can change 'my_array.csv' to your desired filename)\n",
        "file_name1 = 'SFGNV_in.csv'\n",
        "file_name2 = 'SFGNC_in.csv'\n",
        "file_name3 = 'SFGNC_out.csv'\n",
        "file_name4 = 'SFGNV_out.csv'\n",
        "\n",
        "# Concatenate the directory path and the filename to get the full path\n",
        "full_path1 = os.path.join(directory_path, file_name1)\n",
        "full_path2 = os.path.join(directory_path, file_name2)\n",
        "full_path3 = os.path.join(directory_path, file_name3)\n",
        "full_path4 = os.path.join(directory_path, file_name4)\n",
        "\n",
        "# Save the NumPy array as a CSV file\n",
        "np.savetxt(full_path1, X_fgn, delimiter=',')\n",
        "np.savetxt(full_path2, X_cfgn, delimiter=',')\n",
        "np.savetxt(full_path3, Y_data_fc, delimiter=',')\n",
        "np.savetxt(full_path4, Y_data_f, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz5zoMaBx5PU"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots()\n",
        "# ax2 = ax.twiny()\n",
        "\n",
        "for i in range(N):\n",
        "    ax.plot(f,X_21[i,:])\n",
        "ax.minorticks_on()\n",
        "ax.grid()\n",
        "\n",
        "ax.set_xlabel(r'$\\nu$ (MHz)',fontsize=14)\n",
        "ax.set_ylabel(r'$\\delta T_{b}$ (mK)',fontsize=14)\n",
        "ax.set_title('Global 21cm Signal',fontsize=15)\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "# plt.savefig('/home/somnath/akash/QNN21cm/Codes/Plots/21cm_signal.pdf',dpi=100,edgecolor='black')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwTjH_nIx5PV"
      },
      "outputs": [],
      "source": [
        "redshift.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz9Un6cCx5PV"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots()\n",
        "# ax2 = ax.twiny()\n",
        "\n",
        "for i in range(N):\n",
        "    ax.plot(f,X_fgn[i,:])\n",
        "ax.minorticks_on()\n",
        "ax.grid()\n",
        "ax.set_xlabel(r'$\\nu$ (MHz)',fontsize=14)\n",
        "ax.set_ylabel(r'$\\delta T_{b}=T_{21}+T_{FG} + T_{N}$ (mK)',fontsize=14)\n",
        "ax.set_title('Contaminated Signal (Varying)',fontsize=16)\n",
        "ax.set_yscale('log')\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "plt.savefig('/home/somnath/akash/QNN21cm/Codes/Plots/Fore+Sig_var.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gvq3BAf2x5PV"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots()\n",
        "# ax2 = ax.twiny()\n",
        "\n",
        "for i in range(N):\n",
        "    ax.plot(f,X_cfgn[i,:])\n",
        "ax.minorticks_on()\n",
        "ax.grid()\n",
        "ax.set_xlabel(r'$\\nu$ (MHz)',fontsize=14)\n",
        "ax.set_ylabel(r'$\\delta T_{b}=T_{21}+T_{FG} + T_{N}$ (mK)',fontsize=14)\n",
        "ax.set_title('Contaminated Signal (Constant)',fontsize=16)\n",
        "ax.set_yscale('log')\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "plt.savefig('/home/somnath/akash/QNN21cm/Codes/Plots/Fore+Sig_const.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grlwLJSFx5PV"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(1,2,figsize=(12,5))\n",
        "title = ['Contaminated Signal (Constant)',\n",
        "         'Contaminated Signal (Varying)']\n",
        "# fig.text(0.5, 0.02, r'$\\nu$ (MHz)', ha='center',fontsize=14)\n",
        "fig.text(0.07, 0.5, r'$\\delta T_{b}=T_{21}+T_{FG} + T_{N}$ (mK)', va='center', rotation='vertical',fontsize=12)\n",
        "\n",
        "for i in range(N):\n",
        "    ax[0].plot(f,X_cfgn[i,:])\n",
        "    ax[1].plot(f,X_fgn[i,:])\n",
        "\n",
        "for i in range(2):\n",
        "    ax[i].minorticks_on()\n",
        "    ax[i].grid()\n",
        "    ax[i].set_xlabel(r'$\\nu$ (MHz)',fontsize=12)\n",
        "    ax[i].set_title(title[i],fontsize=14)\n",
        "    ax[i].set_yscale('log')\n",
        "    ax[i].tick_params(axis='x', labelsize=12)\n",
        "    ax[i].tick_params(axis='y', labelsize=12)\n",
        "# plt.savefig('/home/somnath/akash/QNN21cm/Codes/Plots/Fore_cv.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDN-1n3Ax5PV"
      },
      "source": [
        "# **Ultility Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0Q66Wxox5PV"
      },
      "outputs": [],
      "source": [
        "#quantum circuit class - Check pennylane source code for more details -\n",
        "#https://docs.pennylane.ai/en/stable/_modules/pennylane/templates/layers/strongly_entangling.html#StronglyEntanglingLayers\n",
        "class StronglyEntanglingLayers(Operation):\n",
        "    num_wires = AnyWires\n",
        "    grad_method = None\n",
        "\n",
        "    def __init__(self, weights, wires, ranges=None, imprimitive=None, id=None):\n",
        "        shape = qml.math.shape(weights)[-3:]\n",
        "\n",
        "        if shape[1] != len(wires):\n",
        "            raise ValueError(\n",
        "                f\"Weights tensor must have second dimension of length {len(wires)}; got {shape[1]}\"\n",
        "            )\n",
        "\n",
        "        if shape[2] != 3:\n",
        "            raise ValueError(\n",
        "                f\"Weights tensor must have third dimension of length 3; got {shape[2]}\"\n",
        "            )\n",
        "\n",
        "        if ranges is None:\n",
        "            if len(wires) > 1:\n",
        "                # tile ranges with iterations of range(1, n_wires)\n",
        "                ranges = tuple((l % (len(wires) - 1)) + 1 for l in range(shape[0]))\n",
        "            else:\n",
        "                ranges = (0,) * shape[0]\n",
        "        else:\n",
        "            ranges = tuple(ranges)\n",
        "            if len(ranges) != shape[0]:\n",
        "                raise ValueError(f\"Range sequence must be of length {shape[0]}; got {len(ranges)}\")\n",
        "            for r in ranges:\n",
        "                if r % len(wires) == 0:\n",
        "                    raise ValueError(\n",
        "                        f\"Ranges must not be zero nor divisible by the number of wires; got {r}\"\n",
        "                    )\n",
        "\n",
        "        self._hyperparameters = {\"ranges\": ranges, \"imprimitive\": imprimitive }\n",
        "\n",
        "        super().__init__(weights, wires=wires, id=id)\n",
        "\n",
        "    @property\n",
        "    def num_params(self):\n",
        "        return 1\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_decomposition(\n",
        "        weights, wires, ranges, imprimitive\n",
        "    ):  # pylint: disable=arguments-differ\n",
        "\n",
        "        n_layers = qml.math.shape(weights)[0]\n",
        "        wires = qml.wires.Wires(wires)\n",
        "        op_list = []\n",
        "        shape = qml.math.shape(weights)[-3:]\n",
        "\n",
        "        for l in range(n_layers):\n",
        "            for i in range(len(wires)):  # pylint: disable=consider-using-enumerate\n",
        "                op_list.append(\n",
        "                    qml.U3(\n",
        "                        weights[..., l, i, 0],\n",
        "                        weights[..., l, i, 1],\n",
        "                        weights[..., l, i, 2],\n",
        "                        wires=wires[i],\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            if len(wires) > 1:\n",
        "                for i in range(len(wires)):\n",
        "                    act_on = wires.subset([i, i + ranges[l]], periodic_boundary=True)\n",
        "                    op_list.append(imprimitive(wires=act_on))\n",
        "\n",
        "        return op_list\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def shape(n_layers, n_wires):\n",
        "\n",
        "        return n_layers, n_wires, 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGOraIy9x5PW"
      },
      "outputs": [],
      "source": [
        "# Defining a function to split the data into training, validation, and test sets\n",
        "def data_split(X, Y, test_size):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    X -> Input\n",
        "    Y -> Output\n",
        "    test_size -> Test data split\n",
        "\n",
        "    Returns:\n",
        "    JAX Numpy arrays of train, validation and test datasets\n",
        "    \"\"\"\n",
        "\n",
        "    # Splitting the data into training and temporary data (1)\n",
        "    x_train, x_1, y_train, y_1 = train_test_split(X, Y, test_size=test_size, random_state=2)\n",
        "\n",
        "    # Further splitting the temporary data (1) into validation and test sets\n",
        "    x_val, x_test, y_val, y_test = train_test_split(x_1, y_1, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Shuffling the training data for randomness\n",
        "    x_train, y_train = shuffle(x_train, y_train, random_state=2)\n",
        "\n",
        "    # Converting the data arrays into JAX arrays\n",
        "    x_train = jnp.array(x_train)\n",
        "    y_train = jnp.array(y_train)\n",
        "    x_val = jnp.array(x_val)\n",
        "    y_val = jnp.array(y_val)\n",
        "    x_test = jnp.array(x_test)\n",
        "    y_test = jnp.array(y_test)\n",
        "\n",
        "    # Returning the split datasets\n",
        "    return x_train, x_val, x_test, y_train, y_val, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrOK7upMx5PW"
      },
      "outputs": [],
      "source": [
        "# Function to initialize parameters for a quantum neural network\n",
        "def params_init(n_layer, n_qubits, Y):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    n_layer -> specifies 1st dimension of weights array\n",
        "    n_qubits -> specifies the 2nd dimension of weights array\n",
        "    Y -> Specifes the shape of the bias array\n",
        "\n",
        "    Returns:\n",
        "    A Dictionary containing the initialized weights and bias\n",
        "    \"\"\"\n",
        "\n",
        "    # Generating a random PRNG key for initialization\n",
        "    key = jax.random.PRNGKey(np.random.randint(0, 1e4))\n",
        "\n",
        "    # Initializing weights randomly using uniform distribution\n",
        "    # Shape of weights: (number of layers, number of qubits per layer, 3)\n",
        "    # 3 represents the parameters required for each qubit in the layer\n",
        "    var_init = jax.random.uniform(key, (n_layer, n_qubits, 3), minval=0, maxval=1)\n",
        "\n",
        "    # Initializing bias as zeros with shape matching the number of output classes\n",
        "    bias_init = jnp.zeros(Y.shape[1])\n",
        "\n",
        "    # Constructing a dictionary to store initialized parameters\n",
        "    params = {\"weights\": var_init, \"bias\": bias_init}\n",
        "\n",
        "    return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDtyBZlpx5PW"
      },
      "outputs": [],
      "source": [
        "def KPCA(data, comps, kernel, inverse=True):\n",
        "    # Initializing KernelPCA with specified parameters\n",
        "    Kpca = KernelPCA(n_components=comps, kernel=kernel, fit_inverse_transform=inverse)\n",
        "\n",
        "    # Performing dimensionality reduction\n",
        "    red = Kpca.fit_transform(data)\n",
        "\n",
        "    # Reconstructing the original data if inverse transformation is enabled\n",
        "    if inverse:\n",
        "        recon = Kpca.inverse_transform(red)\n",
        "        return red, recon\n",
        "    else:\n",
        "        return red, None  # If inverse transformation is disabled, return only reduced data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud0bSQtlx5PW"
      },
      "outputs": [],
      "source": [
        "def pca_fg_filter(data_cube, nfg):\n",
        "    '''\n",
        "    This function will estimate the principal components of the data from the freq covariance and remove\n",
        "    nfg number of modes, which are dominant by FG emission, i.e, with largest eigenvalues of the covariance matrix.\n",
        "    This is PCA fg filter technique.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    data_cube: the image cube. np.ndarray[freq,ra,el]\n",
        "    nfg : int,\n",
        "          number of eigenmodes to remove from the data. Default: nfg=5\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    residual_cube: The FG filtered clean cube\n",
        "    A : The design matrix of shape [nfreq,nfg]. This is the FG operator.\n",
        "    FG_modes : The FG amplitudes of eigenmodes,  of shape [nfg,nra,el].\n",
        "    eigvals: The eigenvalues of the freq cov matrix (sorted as largest value first)\n",
        "    eigvecs: The eigenvectors of the freq cov matrix (sorted as largest value first)\n",
        "\n",
        "    '''\n",
        "#     shp = data_cube.shape # shape of the data cube [nfreq,nRA,nel]\n",
        "#     nfreq, nra, ndec = shp[0], shp[1], shp[2]\n",
        "#     print(f\" nfreq :{nfreq}, Nx : {nra}, Ny: {ndec}\")\n",
        "#     data = data_cube.reshape(nfreq, nra * ndec) # shaping the data in [nfreq, npix] shape\n",
        "\n",
        "    data = data_cube\n",
        "\n",
        "    Cov = np.cov(data) # estimate the freq covariance\n",
        "    eigvals, eigvecs = np.linalg.eigh(Cov) # eigendecomposition\n",
        "\n",
        "    # Sort by eigenvalue\n",
        "    idxs = np.argsort(eigvals)[::-1] # reverse order (biggest eigenvalue first)\n",
        "    eigvals = eigvals[idxs]\n",
        "    eigvecs = eigvecs[:,idxs]\n",
        "\n",
        "    # Construct the design matrix\n",
        "    A = eigvecs[:,:nfg] # (Nfreqs, Nmodes)\n",
        "\n",
        "    # The foreground amplitudes for each line of sight\n",
        "    FG_modes = np.dot(A.T, data) # (Nmodes, Npix)\n",
        "\n",
        "    # Reconstruct the FG map\n",
        "\n",
        "    FG_map = np.dot(A, FG_modes) # Design matrix times FG_modes\n",
        "#     FG_map = FG_map.reshape(nfreq,nra,ndec)\n",
        "\n",
        "    # Subtract the FG map from data\n",
        "    residual_cube = data_cube - FG_map\n",
        "# A, FG_modes.reshape(nfg,nra,ndec), eigvals, eigvecs, FG_map\n",
        "    return residual_cube"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgBaFH2dx5PX"
      },
      "source": [
        "# **Parameter Estimation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-2l3tAUx5PX"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxmEw7BAx5PX"
      },
      "outputs": [],
      "source": [
        "# Define a function for quantum model training\n",
        "def Qmodel(X, Y, n_qubits, n_layer, opt, epoch, batch_size, printing=True, Foreground=False):\n",
        "\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    X -> Input data\n",
        "    Y -> Output data\n",
        "    n_qubits -> No. of qubits required\n",
        "    n_layers -> No. of circuit layers required\n",
        "    opt -> Optimizer used\n",
        "\n",
        "    epoch -> Total epochs for training\n",
        "    batch_size -> Batched input shape for training\n",
        "    Foreground (bool) -> if True, will predict foreground parameters provided that the input data consists the foreground\n",
        "\n",
        "    Returns:\n",
        "    params -> Optimised Weights\n",
        "    train_loss -> Training Loss function\n",
        "    val_loss -> Validation Loss function\n",
        "    test_loss -> Loss between predicted and test data\n",
        "    Y_pre -> Predicted output\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the quantum neural network\n",
        "    def QNN(params, inputs):\n",
        "        weights = params[\"weights\"]\n",
        "        bias = params[\"bias\"]\n",
        "        dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "        @qml.qnode(dev, interface=\"jax\", diff_method='backprop')\n",
        "        def circ():\n",
        "            # Quantum circuit construction\n",
        "            qml.AmplitudeEmbedding(features=inputs, wires=range(n_qubits), normalize=True, pad_with=0.5)\n",
        "            # qml.QFT(wires=range(n_qubits))\n",
        "            StronglyEntanglingLayers(weights, wires=range(n_qubits), imprimitive=qml.ops.CNOT)\n",
        "            if Foreground == True:\n",
        "                out = [qml.expval(qml.PauliZ(i)) for i in range(Y.shape[1])[0::1]]      #exp val of each qubit\n",
        "            else:\n",
        "                out = [qml.expval(qml.PauliZ(i) + qml.PauliZ(i + 1)) for i in range(n_qubits - 1)[0::2]]  #exp value of pair of nearby qubits - giving out an array of 3 elements\n",
        "            return out\n",
        "\n",
        "        # Adding bias\n",
        "        def qnn():\n",
        "            circ_out = circ()\n",
        "            out = []\n",
        "            for i in range(len(circ_out)):\n",
        "                out.append(circ_out[i] + bias[i])\n",
        "            return jnp.array(out)\n",
        "        return qnn()\n",
        "\n",
        "    # Define mean squared error loss function\n",
        "    def mse(observed, predictions):\n",
        "        loss = jnp.sum((observed - predictions) ** 2 / len(observed))\n",
        "        return jnp.mean(loss)\n",
        "\n",
        "    # Define a function for making predictions\n",
        "    def predict(params, features):\n",
        "        preds = QNN(params, features)\n",
        "\n",
        "        preds_np = jnp.asarray(preds).T\n",
        "        return preds_np\n",
        "\n",
        "    # Vectorized prediction function\n",
        "    batched_predict = jax.vmap(predict, in_axes=(None, 0,))\n",
        "\n",
        "    # Define the cost function - since this is used to make predictions jitting is not necessay\n",
        "    def cost(params, features, observed):\n",
        "        preds = batched_predict(params, features)\n",
        "        cost = mse(observed, preds)\n",
        "        return cost\n",
        "\n",
        "    # Define a JIT-compiled version of the cost function - Used durng training and validationg\n",
        "    @jax.jit\n",
        "    def jit_cost(params, features, observed):\n",
        "        preds = batched_predict(params, features)\n",
        "        cost = mse(observed, preds)\n",
        "        return cost\n",
        "\n",
        "    # Update step function - gradient descen optimization\n",
        "    @jax.jit\n",
        "    def update_step(params, opt_state, features, observed):\n",
        "        \"\"\"\n",
        "        Optimization\n",
        "        \"\"\"\n",
        "\n",
        "        train_cost, grads = jax.value_and_grad(jit_cost)(params, features, observed)\n",
        "        updates, opt_state = opt.update(grads, opt_state)\n",
        "        params = optax.apply_updates(params, updates)\n",
        "        return params, opt_state, train_cost\n",
        "\n",
        "    # Function for fitting the model - This is where the training takes place\n",
        "    def fit(params, opt_state, x_train, y_train, x_val, y_val, epoch, batch_size):\n",
        "        \"\"\"\n",
        "        Model Training\n",
        "\n",
        "        Returns:\n",
        "        params -> Optimised Weights and bias\n",
        "        Train loss -> Training loss function\n",
        "        Val loss -> Validation loss function\n",
        "        \"\"\"\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "        num_train = len(x_train)\n",
        "        num_val = len(x_val)\n",
        "        key_t = random.PRNGKey(np.random.randint(0, 1e4))\n",
        "\n",
        "        for i in range(epoch):\n",
        "            key_t, key_v = random.split(key_t)\n",
        "            idx_train = random.choice(key_t, num_train, shape=(batch_size,))\n",
        "            idx_val = random.choice(key_v, num_val, shape=(batch_size,))\n",
        "\n",
        "            x_train_batch = jnp.asarray(x_train[idx_train])\n",
        "            y_train_batch = jnp.asarray(y_train[idx_train])\n",
        "            x_val_batch = jnp.asarray(x_val)\n",
        "            y_val_batch = jnp.asarray(y_val)\n",
        "\n",
        "            start_time = time.time()\n",
        "            params, opt_state, train_cost = update_step(params, opt_state, x_train_batch, y_train_batch)\n",
        "            end_time = time.time()\n",
        "\n",
        "            val_cost = jit_cost(params, x_val_batch, y_val_batch)\n",
        "            epoch_time = end_time - start_time\n",
        "            if printing ==True:\n",
        "                print(\"Epoch: {:5d} | Loss: {:0.7f} | Val_Loss: {:0.7f} | Time: {:0.4f} seconds\".format(i + 1, train_cost, val_cost, epoch_time))\n",
        "\n",
        "            train_loss.append(train_cost)\n",
        "            val_loss.append(val_cost)\n",
        "\n",
        "        return params, train_loss, val_loss\n",
        "\n",
        "    # Splitting data into train, validation, and test sets\n",
        "    x_train, x_val, x_test, y_train, y_val, y_test = data_split(X, Y, 0.2)\n",
        "\n",
        "    # Initializing parameters\n",
        "    params = params_init(n_layer, n_qubits, Y)\n",
        "\n",
        "    # Initializing optimizer state\n",
        "    opt_state = opt.init(params)\n",
        "\n",
        "    # Fitting the model\n",
        "    st = time.time()\n",
        "    params, train_loss, val_loss = fit(params, opt_state, x_train, y_train, x_val, y_val, epoch, batch_size)\n",
        "    tr_t = time.time() - st\n",
        "    if printing ==True:\n",
        "        print(f\" Total Training time = {tr_t // 60} minutes {round(tr_t % 60)} seconds.\")\n",
        "\n",
        "    # Calculating test loss\n",
        "    test_loss = cost(params, x_test, y_test)\n",
        "    # Making predictions on test data\n",
        "    st = time.time()\n",
        "    Y_pre = predict(params, x_test)\n",
        "    te_t = time.time() - st\n",
        "    if printing ==True:\n",
        "        print(f\" Prediction time = {te_t // 60} minutes {round(tr_t % 60)} seconds.\")\n",
        "    out = params, train_loss, val_loss, test_loss, Y_pre\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4lmzwv0x5PX"
      },
      "source": [
        "### **Signal only**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB_f2l9hx5PY"
      },
      "outputs": [],
      "source": [
        "scaler_x = MinMaxScaler(feature_range=(-np.pi,np.pi),clip=True)\n",
        "scaler_x.fit(X_data_nf)\n",
        "X = scaler_x.transform(X_data_nf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MwDxX6yx5Pb"
      },
      "outputs": [],
      "source": [
        "#Normalization\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(Y_data_nf)\n",
        "Y = scaler_y.transform(Y_data_nf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLwNXMjTx5Pb"
      },
      "outputs": [],
      "source": [
        "X_red,X_recon= KPCA(X,comps=128,kernel='rbf',inverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxwS-DYCx5Pc"
      },
      "outputs": [],
      "source": [
        "for i in range(N):\n",
        "    plt.plot(X_red[i,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1prBdtCx5Pc"
      },
      "outputs": [],
      "source": [
        "j = 999\n",
        "plt.plot(X[j,:],color='blue')\n",
        "plt.plot(X_recon[j,:],color='orange')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q20CSmjpx5Pc"
      },
      "outputs": [],
      "source": [
        "reconstruction_error_original = np.mean(np.square(X - X_recon))\n",
        "print(f\"Reconstruction Error - Original Data: {reconstruction_error_original}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bt27q6Ex5Pc"
      },
      "outputs": [],
      "source": [
        "#initial params for the circuit and data split\n",
        "n_qubits = int(np.log2(X_red.shape[1]))\n",
        "n_layer = 40\n",
        "lr_sched = optax.exponential_decay(0.01,1000,0.96)\n",
        "opt = optax.adam(learning_rate=0.01)\n",
        "x_train,x_val,x_test,y_train,y_val,y_test = data_split(X_red,Y,0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sZTuTowx5Pc"
      },
      "outputs": [],
      "source": [
        "#QNN training\n",
        "params,train_loss,val_loss, test_loss,Y_pre = Qmodel(X_red,Y,n_qubits,n_layer,opt,epoch=800,batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMF_k8Ukx5Pc"
      },
      "outputs": [],
      "source": [
        "test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxhifsmEx5Pc"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots()\n",
        "N_p = 1\n",
        "ax.plot(np.convolve(train_loss,np.ones(N_p)/N_p), color=\"red\", label= 'Training Loss')\n",
        "ax.plot(np.convolve(val_loss,np.ones(N_p)/N_p), color=\"green\", label= 'Validation loss')\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"Epoch\",fontsize=14)\n",
        "ax.set_ylabel(\"MSE Loss\",fontsize=14)\n",
        "# ax2=ax.twinx()params\n",
        "ax.grid()\n",
        "# ax2.set_ylabel(\"Validation Loss\",color=\"green\",fontsize=14)\n",
        "# ax.set_yscale('log')\n",
        "# ax2.set_yscale('log')\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "# plt.savefig(\"/home/somnath/akash/QNN21cm/Codes/Plots/Signal_lossfn_2.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5PXVxWZx5Pd"
      },
      "outputs": [],
      "source": [
        "# Compute the output\n",
        "Y_pred = scaler_y.inverse_transform(Y_pre)\n",
        "Y_test = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "\n",
        "r2score= r2_score(y_test, Y_pre, multioutput='uniform_average')\n",
        "fs_r2score= r2_score(y_test[:,0], Y_pre[:,0])\n",
        "print(\"Star_Formation_efficiency_R2score=\", fs_r2score)\n",
        "\n",
        "fx_r2score= r2_score(y_test[:,1], Y_pre[:,1])\n",
        "print(\"X-ray_uncertainty_R2score=\", fx_r2score)\n",
        "\n",
        "Nlw_r2score= r2_score(y_test[:,2], Y_pre[:,2])\n",
        "print(\"Ly-photon_num_R2score=\", Nlw_r2score)\n",
        "\n",
        "\n",
        "#RMSE Score\n",
        "mse = mean_squared_error(y_test, Y_pre, multioutput='raw_values')\n",
        "fs_rmse= sqrt(mse[0])\n",
        "Nlw_rmse= sqrt(mse[2])\n",
        "fx_rmse= sqrt(mse[1])\n",
        "\n",
        "print(\"Star_Formation_efficiency_RMSE=\",fs_rmse)\n",
        "print(\"X-ray_uncertainty_RMSE=\",fx_rmse)\n",
        "print(\"Ly-photon_num_RMSE=\",Nlw_rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC4_21yJx5Pd"
      },
      "outputs": [],
      "source": [
        "r2_score(Y_test,Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTp_hhL7x5Pd"
      },
      "outputs": [],
      "source": [
        "#Saving weights and biases of the model\n",
        "\n",
        "# import os\n",
        "# directory_path = '/home/akash/QNN21cm/Codes'\n",
        "\n",
        "# # Specify the filename (you can change 'my_array.csv' to your desired filename)\n",
        "# file_name_w = 'Weight_JAX.csv'\n",
        "# file_name_b = 'bias_JAX.csv'\n",
        "\n",
        "# # Concatenate the directory path and the filename to get the full path\n",
        "# full_path_w = os.path.join(directory_path, file_name_w)\n",
        "# full_path_b = os.path.join(directory_path, file_name_b)\n",
        "\n",
        "# # Save the NumPy array as a CSV file\n",
        "# np.savetxt(full_path_w, params[\"weights\"].reshape(n_layer*n_qubits*3), delimiter=',')\n",
        "# # Save the NumPy array as a CSV file\n",
        "# np.savetxt(full_path_b, params[\"bias\"], delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TCrCRUpx5Pd"
      },
      "outputs": [],
      "source": [
        "#SAving the prediction output\n",
        "\n",
        "import os\n",
        "directory_path = '/home//akash/QNN21cm/Codes'\n",
        "\n",
        "# Specify the filename (you can change 'my_array.csv' to your desired filename)\n",
        "file_name1 = 'Prediction_21_JAX.csv'\n",
        "\n",
        "# Concatenate the directory path and the filename to get the full path\n",
        "full_path1 = os.path.join(directory_path, file_name1)\n",
        "\n",
        "# Save the NumPy array as a CSV file\n",
        "np.savetxt(full_path1, Y_pred, delimiter=',')\n",
        "# Specify the filename (you can change 'my_array.csv' to your desired filename)\n",
        "file_name2 = 'Test_21_JAX.csv'\n",
        "\n",
        "# Concatenate the directory path and the filename to get the full path\n",
        "full_path2 = os.path.join(directory_path, file_name2)\n",
        "\n",
        "# Save the NumPy array as a CSV file\n",
        "np.savetxt(full_path2, Y_test, delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfQEi48sx5Pd"
      },
      "outputs": [],
      "source": [
        "fsp, fxp, Nlwp = Y_pred.T\n",
        "fst, fxt, Nlwt = Y_test.T\n",
        "title = ['Star Formation Efficiency, f$_{star}$',\n",
        "         'X-Ray Efficiency, f$_{X}$',\n",
        "         'Lyman-'r'$\\alpha$ Photon Number, N$_{lw}$ ($ \\times 10^{5}$)']\n",
        "fig,axe = plt.subplots(1,3,figsize= (17,5))\n",
        "# ticks_1 = np.arange(0,1.2,0.2)\n",
        "# ticks_3 = np.arange(0,0.7,0.1)\n",
        "# ticks = [ticks_1,ticks_1,ticks_3]\n",
        "fig.text(0.5, 0.01, 'Actual Values', ha='center',fontsize=18)\n",
        "fig.text(0.08, 0.5, 'Predicted Values', va='center', rotation='vertical',fontsize=18)\n",
        "\n",
        "sns.regplot(x=fst,y=fsp,ax=axe[0],ci=99, marker=\".\", color=\".3\", line_kws=dict(color=\"r\"))\n",
        "sns.regplot(x=fxt,y=fxp,ax=axe[1],ci=99, marker=\".\", color=\".3\", line_kws=dict(color=\"r\"))\n",
        "sns.regplot(x=Nlwt/1e5,y=Nlwp/1e5,ax=axe[2],ci=99, marker=\".\", color=\".3\", line_kws=dict(color=\"r\"))\n",
        "\n",
        "for i in range(Y_test.shape[1]):\n",
        "    axe[i].set_title(title[i],fontsize=16)\n",
        "    axe[i].grid()\n",
        "    axe[i].tick_params(axis='x', labelsize=13)\n",
        "    axe[i].tick_params(axis='y', labelsize=13)\n",
        "\n",
        "plt.savefig('/home/akash/QNN21cm/Codes/Plots/preds_sonly.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crhb7fl-x5Pd"
      },
      "source": [
        "### **Signal+Foreground**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBiG4jvwx5Pd"
      },
      "source": [
        "#### **Constant Contamination**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSAN_-KVx5Pe"
      },
      "outputs": [],
      "source": [
        "# Use X_cfgn or X_fgn according to your need\n",
        "scaler_x_m = MinMaxScaler(feature_range=(-np.pi,np.pi))\n",
        "scaler_x_m.fit(X_cfgn)\n",
        "X_f = scaler_x_m.transform(X_cfgn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cU730UZx5Pe"
      },
      "outputs": [],
      "source": [
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(Y_data_f)\n",
        "Y_f = scaler_y.transform(Y_data_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0oVVA0wx5Pe"
      },
      "outputs": [],
      "source": [
        "X_red, X_recon =KPCA(X_f,comps=128,kernel='rbf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okeLVipax5Pe"
      },
      "outputs": [],
      "source": [
        "for k in range(10000):\n",
        "    plt.plot(X_red[k,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glVDH1DAx5Pe"
      },
      "outputs": [],
      "source": [
        "j=999\n",
        "plt.plot(X_f[j,:])\n",
        "plt.plot(X_recon[j,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOmnEOwax5Pe"
      },
      "outputs": [],
      "source": [
        "reconstruction_error_original = np.mean(np.square(X_f - X_recon))\n",
        "print(f\"Reconstruction Error - Original Data: {reconstruction_error_original}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Keu02PSTx5Pf"
      },
      "outputs": [],
      "source": [
        "X_red.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWHqY2TRx5Pf"
      },
      "outputs": [],
      "source": [
        "n_qubits = int(np.log2(X_red.shape[1]))\n",
        "n_layer = 40\n",
        "lr_sched = optax.exponential_decay(0.01,1000,0.96)\n",
        "opt = optax.adam(learning_rate=0.01)\n",
        "x_train,x_val,x_test,y_train,y_val,y_test = data_split(X_red,Y,0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjCIla_Hx5Pf"
      },
      "outputs": [],
      "source": [
        "params,train_loss,val_loss, test_loss,Y_pre = Qmodel(X_red,Y,n_qubits,n_layer,opt,epoch=1000,batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkYKcQMax5Pf"
      },
      "outputs": [],
      "source": [
        "test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLniH9uUx5Pf"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots()\n",
        "N_p = 1\n",
        "ax.plot(np.convolve(train_loss,np.ones(N_p)/N_p), color=\"red\", label= 'Training Loss')\n",
        "ax.plot(np.convolve(val_loss,np.ones(N_p)/N_p), color=\"green\", label= 'Validation loss')\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"Epoch\",fontsize=14)\n",
        "ax.set_ylabel(\"MSE Loss\",fontsize=14)\n",
        "# ax2=ax.twinx()\n",
        "ax.grid()\n",
        "# ax2.set_ylabel(\"Validation Loss\",color=\"green\",fontsize=14)\n",
        "ax.set_yscale('log')\n",
        "# ax2.set_yscale('log')\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)\n",
        "# plt.savefig(\"/home/somnath/akash/QNN21cm/Codes/Plots/Sfgn_lossfn_2.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgC5Tqjvx5Pf"
      },
      "outputs": [],
      "source": [
        "# Compute the output\n",
        "Y_pred = scaler_y.inverse_transform(Y_pre)\n",
        "Y_test = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "\n",
        "r2score= r2_score(y_test, Y_pre, multioutput='uniform_average')\n",
        "fs_r2score= r2_score(y_test[:,0], Y_pre[:,0])\n",
        "print(\"Star_Formation_efficiency_R2score=\", fs_r2score)\n",
        "\n",
        "fx_r2score= r2_score(y_test[:,1], Y_pre[:,1])\n",
        "print(\"X-ray_uncertainty_R2score=\", fx_r2score)\n",
        "\n",
        "Nlw_r2score= r2_score(y_test[:,2], Y_pre[:,2])\n",
        "print(\"Ly-photon_num_R2score=\", Nlw_r2score)\n",
        "\n",
        "print(\"tot_r2=\",r2_score(y_test,Y_pre))\n",
        "\n",
        "# a0_r2score= r2_score(y_test[:,3], Y_pre[:,3])\n",
        "# print(\"a0_R2score=\",a0_r2score )\n",
        "\n",
        "# a1_r2score= r2_score(y_test[:,4], Y_pre[:,4])\n",
        "# print(\"a1_R2score=\",a1_r2score)\n",
        "\n",
        "# a2_r2score= r2_score(y_test[:,5], Y_pre[:,5])\n",
        "# print(\"a2_R2score=\",a2_r2score )\n",
        "\n",
        "# a3_r2score= r2_score(y_test[:,6], Y_pre[:,6])\n",
        "# print(\"a3_R2score=\",a3_r2score)\n",
        "\n",
        "from math import sqrt\n",
        "#RMSE Score\n",
        "mse = mean_squared_error(y_test, Y_pre, multioutput='raw_values')\n",
        "fs_rmse= sqrt(mse[0])\n",
        "Nlw_rmse= sqrt(mse[2])\n",
        "fx_rmse= sqrt(mse[1])\n",
        "mean = np.mean([fs_rmse,fx_rmse,Nlw_rmse])\n",
        "print(\"Star_Formation_efficiency_RMSE=\",fs_rmse)\n",
        "print(\"X-ray_uncertainty_RMSE=\",fx_rmse)\n",
        "print(\"Ly-photon_num_RMSE=\",Nlw_rmse)\n",
        "print(\"tot_rmse=\",mean )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35NuRPYRx5Pf"
      },
      "outputs": [],
      "source": [
        "r2_score(y_test,Y_pre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEI9hOW_x5Pg"
      },
      "outputs": [],
      "source": [
        "r2_score(y_test,Y_pre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgY3S9AVx5Pg"
      },
      "outputs": [],
      "source": [
        "# # fsp, Nlwp,Nionp,a0p,a1p,a2p,a3p = Y_pred.T\n",
        "# # fst, Nlwt,Niont,a0t,a1t,a2t,a3t= Y_test.T\n",
        "fsp, fxp, Nlwp = Y_pred.T\n",
        "fst, fxt, Nlwt = Y_test.T\n",
        "title = ['Star Formation Efficiency, f$_{star}$',\n",
        "         'X-Ray Efficiency, f$_{X}$',\n",
        "         'Lyman-'r'$\\alpha$ Photon Number, N$_{lw}$ ($ \\times 10^{5}$)']\n",
        "fig,axe = plt.subplots(1,3,figsize= (17,5))\n",
        "# ticks_1 = np.arange(0,1.2,0.2)\n",
        "# ticks_3 = np.arange(0,0.7,0.1)\n",
        "# ticks = [ticks_1,ticks_1,ticks_3]\n",
        "fig.text(0.5, 0.01, 'Actual Values', ha='center',fontsize=18)\n",
        "fig.text(0.08, 0.5, 'Predicted Values', va='center', rotation='vertical',fontsize=18)\n",
        "\n",
        "sns.regplot(x=fst,y=fsp,ax=axe[0],ci=95, marker=\".\", color=\".3\", line_kws=dict(color=\"r\"))\n",
        "sns.regplot(x=fxt,y=fxp,ax=axe[1],ci=95, marker=\".\", color=\".3\", line_kws=dict(color=\"r\"))\n",
        "sns.regplot(x=Nlwt/1e5,y=Nlwp/1e5,ax=axe[2],ci=95, marker=\".\", color=\".3\", line_kws=dict(color=\"r\"))\n",
        "\n",
        "for i in range(Y_test.shape[1]):\n",
        "    axe[i].set_title(title[i],fontsize=16)\n",
        "    axe[i].grid()\n",
        "    axe[i].tick_params(axis='x', labelsize=12)\n",
        "    axe[i].tick_params(axis='y', labelsize=12)\n",
        "\n",
        "# plt.savefig('/home/akash/QNN21cm/Codes/Plots/preds_sfgnc.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENAkXATIx5Pg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "directory_path = '/home/akash/QNN21cm/Codes'\n",
        "\n",
        "# Specify the filename (you can change 'my_array.csv' to your desired filename)\n",
        "file_name1 = 'Prediction_21cfgn_JAX.csv'\n",
        "\n",
        "# Concatenate the directory path and the filename to get the full path\n",
        "full_path1 = os.path.join(directory_path, file_name1)\n",
        "\n",
        "# Save the NumPy array as a CSV file\n",
        "np.savetxt(full_path1, Y_pred, delimiter=',')\n",
        "# Specify the filename (you can change 'my_array.csv' to your desired filename)\n",
        "file_name2 = 'Test_21cfgn_JAX.csv'\n",
        "\n",
        "# Concatenate the directory path and the filename to get the full path\n",
        "full_path2 = os.path.join(directory_path, file_name2)\n",
        "\n",
        "# Save the NumPy array as a CSV file\n",
        "np.savetxt(full_path2, Y_test, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MldY9eMHx5Pg"
      },
      "source": [
        "#### **Varying Contamination**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkmQuLklx5Pg"
      },
      "outputs": [],
      "source": [
        "res = pca_fg_filter(X_fgn,nfg=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeOelvQWx5Pg"
      },
      "outputs": [],
      "source": [
        "for i in range(N):\n",
        "    plt.plot(f,res[i,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUd8THwTx5Pg"
      },
      "outputs": [],
      "source": [
        "scaler_x_m = MinMaxScaler(feature_range=(-np.pi,np.pi),clip=True)\n",
        "scaler_x_m.fit(res)\n",
        "X_f = scaler_x_m.transform(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR6iFZWAx5Ph"
      },
      "outputs": [],
      "source": [
        "X_red,X_recon = KPCA(X_f,comps=128,kernel='rbf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZnQ0Pz_x5Ph"
      },
      "outputs": [],
      "source": [
        "n_qubits = int(np.log2(X_red.shape[1]))\n",
        "n_layer = 90\n",
        "lr_sched = optax.exponential_decay(0.01,1000,0.96)\n",
        "opt = optax.adam(learning_rate=0.01)\n",
        "x_train,x_val,x_test,y_train,y_val,y_test = data_split(X_red,Y,0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN_5ATItx5Ph"
      },
      "outputs": [],
      "source": [
        "params,train_loss,val_loss, test_loss,Y_pre = Qmodel(X_red,Y,n_qubits,n_layer,opt,epoch=1000,batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d03ium0jx5Ph"
      },
      "outputs": [],
      "source": [
        "test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJUIwaEzx5Ph"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots()\n",
        "N_p = 1\n",
        "ax.plot(np.convolve(train_loss,np.ones(N_p)/N_p), color=\"red\", label= 'Training Loss')\n",
        "ax.plot(np.convolve(val_loss,np.ones(N_p)/N_p), color=\"green\", label= 'Validation loss')\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"Epoch\",fontsize=14)\n",
        "ax.set_ylabel(\"MSE Loss\",fontsize=14)\n",
        "# ax2=ax.twinx()\n",
        "ax.grid()\n",
        "# ax2.set_ylabel(\"Validation Loss\",color=\"green\",fontsize=14)\n",
        "ax.set_yscale('log')\n",
        "# ax2.set_yscale('log')\n",
        "ax.tick_params(axis='x', labelsize=12)\n",
        "ax.tick_params(axis='y', labelsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3_Lrbs3x5Ph"
      },
      "outputs": [],
      "source": [
        "# Compute the output\n",
        "Y_pred = scaler_y.inverse_transform(Y_pre)\n",
        "Y_test = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "\n",
        "r2score= r2_score(y_test, Y_pre, multioutput='uniform_average')\n",
        "fs_r2score= r2_score(y_test[:,0], Y_pre[:,0])\n",
        "print(\"Star_Formation_efficiency_R2score=\", fs_r2score)\n",
        "\n",
        "fx_r2score= r2_score(y_test[:,1], Y_pre[:,1])\n",
        "print(\"X-ray_uncertainty_R2score=\", fx_r2score)\n",
        "\n",
        "Nlw_r2score= r2_score(y_test[:,2], Y_pre[:,2])\n",
        "print(\"Ly-photon_num_R2score=\", Nlw_r2score)\n",
        "\n",
        "print(\"tot_r2=\",r2_score(y_test,Y_pre))\n",
        "\n",
        "\n",
        "from math import sqrt\n",
        "#RMSE Score\n",
        "mse = mean_squared_error(y_test, Y_pre, multioutput='raw_values')\n",
        "fs_rmse= sqrt(mse[0])\n",
        "Nlw_rmse= sqrt(mse[2])\n",
        "fx_rmse= sqrt(mse[1])\n",
        "mean = np.mean([fs_rmse,fx_rmse,Nlw_rmse])\n",
        "print(\"Star_Formation_efficiency_RMSE=\",fs_rmse)\n",
        "print(\"X-ray_uncertainty_RMSE=\",fx_rmse)\n",
        "print(\"Ly-photon_num_RMSE=\",Nlw_rmse)\n",
        "print(\"tot_rmse=\",mean )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOFhf5mHx5Ph"
      },
      "outputs": [],
      "source": [
        "# # fsp, Nlwp,Nionp,a0p,a1p,a2p,a3p = Y_pred.T\n",
        "# # fst, Nlwt,Niont,a0t,a1t,a2t,a3t= Y_test.T\n",
        "fsp, fxp, Nlwp = Y_pred.T\n",
        "fst, fxt, Nlwt = Y_test.T\n",
        "title = ['Star Formation Efficiency, f$_{star}$',\n",
        "         'X-Ray Efficiency, f$_{X}$',\n",
        "         'Lyman-'r'$\\alpha$ Photon Number, N$_{lw}$ ($ \\times 10^{5}$)']\n",
        "fig,axe = plt.subplots(1,3,figsize= (17,5))\n",
        "# ticks_1 = np.arange(0,1.2,0.2)\n",
        "# ticks_3 = np.arange(0,0.7,0.1)\n",
        "# ticks = [ticks_1,ticks_1,ticks_3]\n",
        "fig.text(0.5, 0.01, 'Actual Values', ha='center',fontsize=18)\n",
        "fig.text(0.08, 0.5, 'Predicted Values', va='center', rotation='vertical',fontsize=18)\n",
        "\n",
        "sns.regplot(x=fst,y=fsp,ax=axe[0],ci=95, marker=\".\", color=\".3\", line_kws=dict(color=\"r\"))\n",
        "sns.regplot(x=fxt,y=fxp,ax=axe[1],ci=95, marker=\".\", color=\".3\", line_kws=dict(color=\"r\"))\n",
        "sns.regplot(x=Nlwt/1e5,y=Nlwp/1e5,ax=axe[2],ci=95, marker=\".\", color=\".3\", line_kws=dict(color=\"r\"))\n",
        "\n",
        "for i in range(Y_test.shape[1]):\n",
        "    axe[i].set_title(title[i],fontsize=16)\n",
        "    axe[i].grid()\n",
        "    axe[i].tick_params(axis='x', labelsize=12)\n",
        "    axe[i].tick_params(axis='y', labelsize=12)\n",
        "\n",
        "# plt.savefig('/home/akash/QNN21cm/Codes/Plots/preds_sfgnv.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyVQnEz8x5Pi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "directory_path = '/home/akash/QNN21cm/Codes'\n",
        "\n",
        "# Specify the filename (you can change 'my_array.csv' to your desired filename)\n",
        "file_name1 = 'Prediction_21vfgn_JAX.csv'\n",
        "\n",
        "# Concatenate the directory path and the filename to get the full path\n",
        "full_path1 = os.path.join(directory_path, file_name1)\n",
        "\n",
        "# Save the NumPy array as a CSV file\n",
        "np.savetxt(full_path1, Y_pred, delimiter=',')\n",
        "# Specify the filename (you can change 'my_array.csv' to your desired filename)\n",
        "file_name2 = 'Test_21vfgn_JAX.csv'\n",
        "\n",
        "# Concatenate the directory path and the filename to get the full path\n",
        "full_path2 = os.path.join(directory_path, file_name2)\n",
        "\n",
        "# Save the NumPy array as a CSV file\n",
        "np.savetxt(full_path2, Y_test, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnIL28s5x5Pi"
      },
      "source": [
        "### **Generalization with less training set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7AMRazox5Pi"
      },
      "outputs": [],
      "source": [
        "n_qubits = int(np.log2(X_red.shape[1]))\n",
        "n_layer = 40\n",
        "lr_sched = optax.exponential_decay(0.01,1000,0.96)\n",
        "opt = optax.adam(learning_rate=0.01)\n",
        "x_train,x_val,x_test,y_train,y_val,y_test = data_split(X_red,Y,0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3gdMHrZx5Pi"
      },
      "outputs": [],
      "source": [
        "def multi_train(num,epoch,batch):\n",
        "    # np.random.seed(43)\n",
        "    idx = np.random.randint(0, 10000, (num,))\n",
        "    x_train, x_val, x_test, y_train, y_val, y_test = data_split(X_red[idx],Y[idx],test_size=0.2)\n",
        "    params,train_loss,val_loss, test_loss,Y_pre = Qmodel(X_red[idx],Y[idx],n_qubits,n_layer,opt,epoch=epoch,batch_size=batch,printing=False)\n",
        "    loss= np.array(train_loss)[-20:].mean()\n",
        "    val_loss = np.array(val_loss)[-20:].mean()\n",
        "    gen_err = val_loss-loss\n",
        "    r2score= r2_score(y_test, Y_pre, multioutput='uniform_average')\n",
        "    mse = mean_squared_error(y_test, Y_pre, multioutput='raw_values')\n",
        "    fs_rmse= sqrt(mse[0])\n",
        "    Nlw_rmse= sqrt(mse[2])\n",
        "    fx_rmse= sqrt(mse[1])\n",
        "    r_score = r2_score(Y_pre,y_test)\n",
        "    print(r_score)\n",
        "    mean = np.mean([fs_rmse,fx_rmse,Nlw_rmse])\n",
        "    print(mean)\n",
        "    return r_score, mean, gen_err"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mduGrsalx5Pi"
      },
      "outputs": [],
      "source": [
        "r1,m1,gen1 = multi_train(100,200,32)\n",
        "r2,m2,gen2 = multi_train(500,200,64)\n",
        "r3,m3,gen3 = multi_train(1000,200,128)\n",
        "r4,m4,gen4 = multi_train(3000,200,256)\n",
        "r5,m5,gen5 = multi_train(7000,500,512)\n",
        "r6,m6,gen6 = multi_train(10000,500,512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyON8Tgjx5Pi"
      },
      "outputs": [],
      "source": [
        "dat_size = np.array([100,500,1000,3000,7000,10000])\n",
        "r_err = np.array([r1,r2,r3,r4,r5,r6])\n",
        "m_err = np.array([m1,m2,m3,m4,m5,m6])\n",
        "gen_err = np.array([gen1,gen2,gen3,gen4,gen5,gen6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYwkP3l1x5Pj"
      },
      "outputs": [],
      "source": [
        "err = np.array([r_err,m_err,gen_err])\n",
        "label = [r'R$^2$ Score','RMSE', 'Generalization Error']\n",
        "y_ax = [r'R$^2$ Score','RMSE',None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Vt9qJyx5Pj"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(1,3,figsize=(15,5))\n",
        "for i in range(3):\n",
        "  ax[i].plot(dat_size,err[i],marker='o',color='green',label=label[i])\n",
        "  ax[i].grid()\n",
        "  ax[i].legend()\n",
        "  ax[i].set_ylabel(y_ax[i])\n",
        "  ax[i].set_xlabel('Training Set Size')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN3EIkD5x5Pj"
      },
      "outputs": [],
      "source": [
        "# Specify the filename (you can change 'my_array.csv' to your desired filename)\n",
        "directory_path = '/home/akash/QNN21cm/Codes'\n",
        "file_name1 = 'Gen_Err_3.csv'\n",
        "\n",
        "# Concatenate the directory path and the filename to get the full path\n",
        "full_path1 = os.path.join(directory_path, file_name1)\n",
        "\n",
        "# Save the NumPy array as a CSV file\n",
        "np.savetxt(full_path1, err, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVeYVccDx5Pj"
      },
      "source": [
        "# **Benchmarking**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXDvDSgGx5Pj"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "fruits = ['A100 80GB', 'A30 24GB', 'GTX 1070', 'CPU']\n",
        "t_all = np.array([3,4.5,6.75,19])\n",
        "# bar_labels = ['red', 'blue', '_red', 'orange']\n",
        "bar_colors = ['tab:green', 'tab:blue', 'tab:red', 'tab:orange']\n",
        "\n",
        "ax.bar(fruits, t_all, color=bar_colors)\n",
        "\n",
        "ax.set_ylabel('JQNN Model Training Time (in minutes)')\n",
        "ax.set_title('Benchmarking')\n",
        "ax.grid()\n",
        "# ax.legend(title='Benchmarking')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}